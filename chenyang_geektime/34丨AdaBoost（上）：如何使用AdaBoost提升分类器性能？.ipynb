{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#基本概念\" data-toc-modified-id=\"基本概念-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>基本概念</a></span><ul class=\"toc-item\"><li><span><a href=\"#算法示例\" data-toc-modified-id=\"算法示例-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>算法示例</a></span></li></ul></li><li><span><a href=\"#总结\" data-toc-modified-id=\"总结-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>总结</a></span></li><li><span><a href=\"#练习\" data-toc-modified-id=\"练习-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>练习</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集成算法：投票学习（bagging）和再学习（boosting）。\n",
    "\n",
    "bagging：各模型分别对数据进行分类，而后选择出现次数最多的那个类作为最终的分类结果。\n",
    "\n",
    "boosting：将各个模型进行分权融合，形成一个超级模型（强分类器），而后使用超级模型做分类。<br>Boosting 的含义是提升，作用是每次训练时都是对上一次训练进行改进提升。因此，实际上是不断优化前一个模型。\n",
    "\n",
    "AdaBoosting 算法，Adaptive Boosting，自适应提升算法。其原理是通过训练多个弱分类器，而后将其组成一个强分类器。原理图如下：<img src=\"https://static001.geekbang.org/resource/image/8e/b4/8e88b8a952d872ea46b7dd7c084747b4.jpg\" style=\"width:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其相关数学公式如下：![](https://static001.geekbang.org/resource/image/58/4f/58f7ff50e49f3cd96f6d4f0e590da04f.png)\n",
    "\n",
    "其中：\n",
    "- Gi(x)：弱分类器；\n",
    "- αi：弱分类器在强分类器中的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个问题:\n",
    "1. 在每次迭代训练中，如何得到最优弱分类器？\n",
    "1. 如何计算每个弱分类器在强分类器中的权重？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "弱分类器在强分类器中的权重：<br>\n",
    "如果弱分类器的分类效果好，那么权重应该比较大；如果弱分类器的效果一般，权重应该降低。用数学公式表示如下：![](https://static001.geekbang.org/resource/image/58/4f/58f7ff50e49f3cd96f6d4f0e590da04f.png)<br>其中 ei 代表第 i 个分类器的分类错误率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "在每次训练迭代过程中选择最优弱分类器：<br>实际上，AdaBoost 算法是通过改变样本的数据分布来实现的。AdaBoost 会判断每次训练的样本是否正确分类：如果正确分类的话，降低其权重；如果错误，增加其权重。再基于上次得到的分类准确率，来确定这次训练样本中每个样本的权重。然后，将修改过权重的新数据集传递给下一层的分类器进行训练。<br>这样做的好处是，通过每轮训练样本的动态权重，可以让训练的焦点集中到难分类的样本上，最终得到的弱分类器的组合更容易得到更高的分类准确率。<br>\n",
    "（个人：实际上，这就是：如果某样本分类对了，那就少花资源在该样本上；如果分类错了，那就多花资源在该资源上。这样，通过不断迭代，最终分类正确的样本只会越来越多。）\n",
    "\n",
    "![](https://static001.geekbang.org/resource/image/d9/b6/d9b32e1d065e39861f266709640b2bb6.png)<br>\n",
    "<br>其中，$D_{k+1}$ 代表第 k+1 轮训练中，样本的权重集合。$W_{k+1,1}$ 代表第 k+1 轮中第一个样本的权重，以此类推 $W_{k+1,N}$ 代表第 k+1 轮中第 N 个样本的权重。\n",
    "<br>\n",
    "第 k+1 轮中的样本权重，可以根据该样本在第 k 轮的权重以及第 k  个分类器的准确率而定，具体公式如下：![](https://static001.geekbang.org/resource/image/1a/58/1a6c650c3b7aa6d44cccf3b9dff81258.png)<br>（囧。看不懂这个公式 --。）<br>补充：<br>$Z_k$ 是归一化因子；<br>$y_i$ 是标记集合${-1,+1}$,1 代表分类正确，-1 代表分类错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据：![](https://static001.geekbang.org/resource/image/73/38/734c8272df1f96903be1777733a10f38.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 10 个样本的权重为 1/10，此时 D1=(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
    "1. 假设此时有三个基础分类器：![](https://static001.geekbang.org/resource/image/32/a4/325756eb08b5b3fd55402c9a8ba4dca4.png)<br>\n",
    "则可得到三个基础分类器的错误率分别为：\n",
    "    - $f_1$：0.3\n",
    "    - $f_2$：0.4\n",
    "    - $f_3$：0.3\n",
    "1. 通过第二步可知，$f_1$ 和 $f_3$ 的错误率最低。再假设此时选取 $f_1$ 作为最优分类器，则第一轮训练可得：![](https://static001.geekbang.org/resource/image/3d/fb/3dd329577aef1a810a1c130095a3e0fb.png)<br>同时可得分类器权重为：![](https://static001.geekbang.org/resource/image/f9/60/f92e515d7ad7c1ee5f3bf45574bf3060.png)\n",
    "1. 根据所得权重值，代入 $W_{k+1,i}$ 和 $D_{k+1}$ 的公式，可得到新的权重值：D2=(0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.1666, 0.1666, 0.1666, 0.0715)。\n",
    "1. 继续进行训练，直到训练次数（3 次）达到上限，所得最终的强分类器 G(x) = 0.4236G1(x) + 0.6496G2(x) + 0.7514G3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static001.geekbang.org/resource/image/10/00/10ddea37b3fdea2ec019f38b59ac6b00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 如何理解 AdaBoost 中弱分类器；\n",
    "1. AdaBoost 算法如何训练弱分类器从而得到一个强分类器？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "弱分类器：分类器正确率高于盲猜概率。\n",
    "\n",
    "AdaBoost 算法：在每次迭代中，选取最优弱分类器，最后把选取的分类器组合形成强分类器。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
